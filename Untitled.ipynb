{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained statistical learning plus experimental data predicts the functional effect of mutations in a model enzyme \n",
    "\n",
    "## Prep input files \n",
    "\n",
    "First, we'll make models of all of the enzymes using Rosetta. All we need is a wild type PDB structure, `bglb.pdb`, and a list of mutations that we have kinetic data for, `mutant_list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MutateResidue mover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this one for MutateResidue \n",
    "\n",
    "from Bio.SeqUtils import IUPACData\n",
    "nstruct = 100\n",
    "\n",
    "with open( 'mutant_list' ) as fn:\n",
    "    mutants = [ i.strip() for i in fn.readlines() if len( i ) > 1 ] \n",
    "    print len( mutants ), 'mutants'\n",
    "\n",
    "nstruct = 100\n",
    "\n",
    "runs = [\n",
    "    # '-s input_pdb/{}.pdb -parser:script_vars target={} -suffix _{} \\n'.format( mutant, mutant[1:-1], i ) )\n",
    "    '-parser:script_vars target={} new_res={} -suffix _{}_{:04d}\\n'.format( m[1:-1], IUPACData.protein_letters_1to3[ m[-1] ].upper(), m, i )\n",
    "    for i in range( nstruct )\n",
    "    for m in mutants \n",
    "]\n",
    "\n",
    "with open( 'list', 'w' ) as fn:\n",
    "    fn.write( ''.join( runs ) )\n",
    "    \n",
    "! wc -l list \n",
    "! head -2 list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the simulations on Cabernet with SLURM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# run the simulations on Cabernet w/ SLURM \n",
    " \n",
    "runs=$( wc -l list | cut -d' ' -f1 )\n",
    "echo $runs runs \n",
    "echo sbatch -p gc128 --array=1-$runs sub.sh\n",
    "#sbatch -p gc128 --array=1-$runs sub.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data from the modeling simulations and combine with experimental data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import pandas\n",
    "\n",
    "sfs = [ pandas.read_csv( i, sep='\\s+' ) for i in glob( 'out/*sc' ) ]\n",
    "sf = pandas.concat( sfs )\n",
    "sf['name'] = sf.description.str.split( '_' ).str[ 1 ]\n",
    "sf.to_csv( 'scorefile.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! wc -l scorefile.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf = pandas.read_csv( 'scorefile.csv', index_col='description' )\n",
    "sf.sample( 40 ) \n",
    "\n",
    "def low_10( df ):\n",
    "    return df.sort_values( by='total_score' ).head( 10 ).mean()\n",
    "\n",
    "grouped = sf.groupby( 'name' )\n",
    "low10 = grouped.apply( low_10 )\n",
    "#low10.index = low10.name \n",
    "\n",
    "print len( low10 ), 'models in scorefile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import log, inf, nan\n",
    "\n",
    "# experimental data \n",
    "experimental = pandas.read_csv( '../bagel-data/clean_data/clean_for_pandas.csv', index_col='name' )\n",
    "\n",
    "# log and relative to wt \n",
    "wt = experimental.loc[ 'BglB' ]\n",
    "experimental.drop( [ 'BglB' ] )\n",
    "log_diff = log( experimental / wt )\n",
    "\n",
    "print len( log_diff.kcat.dropna() ), 'kcat'\n",
    "print len( log_diff.km.dropna() ), 'km'\n",
    "print len( log_diff.kcatkm.dropna() ), 'kcat/km'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join with models \n",
    "joined = low10.join( log_diff )\n",
    "print len( joined ), 'joined total'\n",
    "\n",
    "# make a list of what we don't have data for \n",
    "# predict that list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have 10 models (the lowest 10 by total_energy out of 100 simulations) of each protein, joined with experimental data. We don't have all pieces of experimental data for each protein, so there are some NaNs in the above dataframe, which scikit-learn doesn't deal very well with. We will clean up the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "constants = [ 'kcat', 'km', 'kcatkm' ]\n",
    "\n",
    "# clean up data for sklearn\n",
    "x_cols = [ u'total_score', u'fa_rep', u'hbond_sc', u'tot_pstat_pm',\n",
    "       u'tot_nlpstat_pm', u'tot_burunsat_pm', u'tot_hbond_pm',\n",
    "       u'tot_NLconts_pm', u'tot_nlsurfaceE_pm', u'tot_total_charge',\n",
    "       u'tot_total_pos_charges', u'tot_total_neg_charges', u'tot_seq_recovery',\n",
    "       u'SR_1_total_score', u'SR_1_fa_rep', u'SR_1_hbond_sc',\n",
    "       u'SR_1_hbond_pm', u'SR_1_burunsat_pm',\n",
    "       u'SR_1_pstat_pm', u'SR_1_nlpstat_pm', u'SR_2_total_score',\n",
    "       u'SR_2_fa_rep', u'SR_2_hbond_sc', u'SR_2_all_cst', u'SR_2_hbond_pm',\n",
    "       u'SR_2_burunsat_pm', u'SR_2_pstat_pm', u'SR_2_nlpstat_pm',\n",
    "       u'SR_3_total_score', u'SR_3_fa_rep', u'SR_3_hbond_sc', \n",
    "       u'SR_3_hbond_pm', u'SR_3_burunsat_pm', u'SR_3_pstat_pm',\n",
    "       u'SR_3_nlpstat_pm', u'SR_4_total_score', u'SR_4_fa_rep',\n",
    "       u'SR_4_hbond_sc', u'SR_4_hbond_pm',\n",
    "       u'SR_4_burunsat_pm', u'SR_4_pstat_pm', u'SR_4_nlpstat_pm',\n",
    "       u'SR_5_total_score', u'SR_5_fa_rep', u'SR_5_hbond_sc', u'SR_5_all_cst',\n",
    "       u'SR_5_interf_E_1_2', u'SR_5_dsasa_1_2', u'SR_5_hbond_pm',\n",
    "       u'SR_5_burunsat_pm', ]\n",
    "\n",
    "for constant in constants:\n",
    "    work = joined[ x_cols + [ constant ] ]\n",
    "    work = work.replace( [ inf, -inf ], nan )\n",
    "    work = work.dropna()\n",
    "    work.to_csv( 'training_sets/{}.csv'.format( constant ) )\n",
    "    # now we have 3 clean CSVs, one for each constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes our cleaning up the data to use in machine learning. In the next steps, we will evaluate the performance of machine learning algorithms in predicting the functional effect of each mutation, in terms of its effect on kcat, km, and kcat/km. \n",
    "\n",
    "## Elastic net regression gives PCC values of 0.7-0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "constants = [ 'kcat', 'km', 'kcatkm' ]\n",
    "for constant in constants:\n",
    "    df = pandas.read_csv( 'training_sets/{}.csv'.format( constant ), index_col='name' )\n",
    "    print len( df ), 'models for constant', constant\n",
    "    y = df[ constant ]\n",
    "    X = df.drop( constant, axis=1 )\n",
    "        \n",
    "    import matplotlib.pyplot as plt \n",
    "    %matplotlib inline\n",
    "\n",
    "    skf = StratifiedKFold( y, 10 )\n",
    "    net = ElasticNetCV( l1_ratio=[.1, .5, .7, .9, .95, .99, 1], cv=skf )\n",
    "    bag = BaggingRegressor( net, n_estimators=10, n_jobs=10 )\n",
    "    bag.fit( X, y )\n",
    "\n",
    "    #weights = pandas.DataFrame( zip( X.columns, bag.estimators_[0].best_estimator_.coef_ ), columns=['feature', 'weight'] )\n",
    "    preds = bag.predict( X )\n",
    "\n",
    "    #print weights[ ( weights.weight > 0 )].sort( 'weight', ascending=False )\n",
    "    print 'Constant', constant\n",
    "    print 'PCC={:2.2f}'.format( pearsonr( preds, y )[0] )\n",
    "\n",
    "    plt.figure( figsize=(4,4) )\n",
    "    plt.scatter( preds, y, marker='.', color='k' )\n",
    "    plt.xlabel( 'Predicted' )\n",
    "    plt.ylabel( 'Actual' )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Expression benchmark \n",
    "\n",
    "See if we can predict soluble expression given the set of 50 features output by Rosetta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_cols = [ u'total_score', u'fa_rep', u'hbond_sc', \n",
    "       u'tot_pstat_pm', u'tot_nlpstat_pm', u'tot_burunsat_pm', u'tot_hbond_pm',\n",
    "       u'tot_NLconts_pm', u'tot_nlsurfaceE_pm', u'tot_total_charge',\n",
    "       u'tot_total_pos_charges', u'tot_total_neg_charges', u'tot_seq_recovery',\n",
    "       u'SR_1_total_score', u'SR_1_fa_rep', u'SR_1_hbond_sc',\n",
    "       u'SR_1_hbond_pm', u'SR_1_burunsat_pm',\n",
    "       u'SR_1_pstat_pm', u'SR_1_nlpstat_pm', u'SR_2_total_score',\n",
    "       u'SR_2_fa_rep', u'SR_2_hbond_sc', u'SR_2_all_cst', u'SR_2_hbond_pm',\n",
    "       u'SR_2_burunsat_pm', u'SR_2_pstat_pm', u'SR_2_nlpstat_pm', u'SR_3',\n",
    "       u'SR_3_total_score', u'SR_3_fa_rep', u'SR_3_hbond_sc', u'SR_3_all_cst',\n",
    "       u'SR_3_hbond_pm', u'SR_3_burunsat_pm', u'SR_3_pstat_pm',\n",
    "       u'SR_3_nlpstat_pm', u'SR_4', u'SR_4_total_score', u'SR_4_fa_rep',\n",
    "       u'SR_4_hbond_sc', u'SR_4_all_cst', u'SR_4_hbond_pm',\n",
    "       u'SR_4_burunsat_pm', u'SR_4_pstat_pm', u'SR_4_nlpstat_pm', u'SR_5',\n",
    "       u'SR_5_total_score', u'SR_5_fa_rep', u'SR_5_hbond_sc', u'SR_5_all_cst',\n",
    "       u'SR_5_interf_E_1_2', u'SR_5_dsasa_1_2', u'SR_5_hbond_pm',\n",
    "       u'SR_5_burunsat_pm', u'expression' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas \n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def low10( df ):\n",
    "    return df.sort_values( by='total_score' ).head( 10 ) #.mean()\n",
    "\n",
    "thermo = pandas.read_csv( 'data_sets/expression_cat.csv', index_col='name' ) \n",
    "sf = pandas.read_csv( 'data_sets/scorefile.csv' ) \n",
    "sf['name'] = sf.description.str.split( '_' ).str[ 1 ]\n",
    "\n",
    "grouped = sf.groupby( 'name' )\n",
    "low10 = grouped.apply( low10 )\n",
    "low10.index = low10.name \n",
    "\n",
    "x = low10.join( thermo ).dropna()\n",
    "x = x[ keep_cols ] \n",
    "\n",
    "y = x.expression.round().astype( bool )\n",
    "#y = x.expression * 2 # for multi-class\n",
    "X = x.drop( u'expression', axis=1 )\n",
    "\n",
    "clf = svm.SVC( kernel='linear' )\n",
    "bag = BaggingClassifier( clf, n_estimators=10, n_jobs=-1 )\n",
    "bag.fit( X, y ) \n",
    "\n",
    "print 'model score', bag.score( X, y ) \n",
    "preds = bag.predict( X ) \n",
    "scores = bag.decision_function( X ) \n",
    "fpr, tpr, __ = roc_curve( y, scores ) \n",
    "\n",
    "plt.figure( figsize=(4,4) )\n",
    "plt.plot( fpr, tpr ) \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.02, 1.02])\n",
    "plt.ylim([-0.02, 1.02])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAEZCAYAAABW7tqnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10689c150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# blind predictions \n",
    "\n",
    "blind_data = pandas.read_csv( 'data_sets/expression_data.csv', index_col='name' )\n",
    "\n",
    "def low10( df ):\n",
    "    return df.sort_values( by='total_score' ).head( 10 ) #.mean()\n",
    "\n",
    "sf = pandas.read_csv( 'data_sets/scorefile.csv' ) \n",
    "sf['name'] = sf.description.str.split( '_' ).str[ 1 ]\n",
    "\n",
    "grouped = sf.groupby( 'name' )\n",
    "low10 = grouped.apply( low10 )\n",
    "low10.index = low10.name\n",
    "joined_blind = low10.join( blind_data ).dropna() \n",
    "print len( joined_blind) # should be 10 * ( n_samples ) \n",
    "\n",
    "little_x = joined_blind[ keep_cols ]  \n",
    "X_test = little_x.drop( 'expression', axis=1 ) \n",
    "y_test = joined_blind.expression.astype( bool ) \n",
    "\n",
    "test_predictions = bag.predict( X_test ) \n",
    "scores = bag.decision_function( X_test ) \n",
    "fpr, tpr, __ = roc_curve( y_test, scores ) \n",
    "\n",
    "plt.figure( figsize=(4,4) )\n",
    "plt.plot( fpr, tpr, color='r' ) \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.02, 1.02])\n",
    "plt.ylim([-0.02, 1.02])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "###############################################################################\n",
    "# Data IO and generation\n",
    "\n",
    "# import some data to play with\n",
    "import pandas \n",
    "\n",
    "def low10( df ):\n",
    "    return df.sort_values( by='total_score' ).head( 10 ).mean()\n",
    "\n",
    "thermo = pandas.read_csv( 'data_sets/expression_data.csv', index_col='name' ) \n",
    "sf = pandas.read_csv( 'scorefile.csv' ) \n",
    "sf['name'] = sf.description.str.split( '_' ).str[ 1 ]\n",
    "\n",
    "grouped = sf.groupby( 'name' )\n",
    "low10 = grouped.apply( low10 )\n",
    "#low10.index = low10.name \n",
    "x = low10.join( thermo ).dropna()\n",
    "\n",
    "keep_cols = [ u'total_score', u'fa_rep', u'hbond_sc', \n",
    "       u'tot_pstat_pm', u'tot_nlpstat_pm', u'tot_burunsat_pm', u'tot_hbond_pm',\n",
    "#        u'tot_NLconts_pm', u'tot_nlsurfaceE_pm', u'tot_total_charge',\n",
    "#        u'tot_total_pos_charges', u'tot_total_neg_charges', u'tot_seq_recovery',\n",
    "#        u'SR_1_total_score', u'SR_1_fa_rep', u'SR_1_hbond_sc',\n",
    "#        u'SR_1_hbond_pm', u'SR_1_burunsat_pm',\n",
    "#        u'SR_1_pstat_pm', u'SR_1_nlpstat_pm', u'SR_2_total_score',\n",
    "#        u'SR_2_fa_rep', u'SR_2_hbond_sc', u'SR_2_all_cst', u'SR_2_hbond_pm',\n",
    "#        u'SR_2_burunsat_pm', u'SR_2_pstat_pm', u'SR_2_nlpstat_pm', u'SR_3',\n",
    "#        u'SR_3_total_score', u'SR_3_fa_rep', u'SR_3_hbond_sc', u'SR_3_all_cst',\n",
    "#        u'SR_3_hbond_pm', u'SR_3_burunsat_pm', u'SR_3_pstat_pm',\n",
    "#        u'SR_3_nlpstat_pm', u'SR_4', u'SR_4_total_score', u'SR_4_fa_rep',\n",
    "#        u'SR_4_hbond_sc', u'SR_4_all_cst', u'SR_4_hbond_pm',\n",
    "#        u'SR_4_burunsat_pm', u'SR_4_pstat_pm', u'SR_4_nlpstat_pm', u'SR_5',\n",
    "#        u'SR_5_total_score', u'SR_5_fa_rep', u'SR_5_hbond_sc', u'SR_5_all_cst',\n",
    "       u'SR_5_interf_E_1_2', u'SR_5_dsasa_1_2', u'SR_5_hbond_pm',\n",
    "       u'SR_5_burunsat_pm', u'expression' ]\n",
    "\n",
    "x = x[ keep_cols ] \n",
    "\n",
    "y = x.expression.round().astype( bool )\n",
    "X = x.drop( u'expression', axis=1 )\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X = np.c_[X] #, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "###############################################################################\n",
    "# Classification and ROC analysis\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(y, n_folds=10)\n",
    "classifier = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
    "         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "###############################################################################\n",
    "# Data IO and generation\n",
    "\n",
    "# import some data to play with\n",
    "import pandas \n",
    "\n",
    "def low10( df ):\n",
    "    return df.sort_values( by='total_score' ).head( 10 ).mean()\n",
    "\n",
    "thermo = pandas.read_csv( 'data_sets/expression_data.csv', index_col='name' ) \n",
    "sf = pandas.read_csv( 'scorefile.csv' ) \n",
    "sf['name'] = sf.description.str.split( '_' ).str[ 1 ]\n",
    "\n",
    "grouped = sf.groupby( 'name' )\n",
    "low10 = grouped.apply( low10 )\n",
    "#low10.index = low10.name \n",
    "x = low10.join( thermo ).dropna()\n",
    "\n",
    "keep_cols = [ u'total_score', u'fa_rep', u'hbond_sc', \n",
    "       u'tot_pstat_pm', u'tot_nlpstat_pm', u'tot_burunsat_pm', u'tot_hbond_pm',\n",
    "       u'tot_NLconts_pm', u'tot_nlsurfaceE_pm', u'tot_total_charge',\n",
    "       u'tot_total_pos_charges', u'tot_total_neg_charges', u'tot_seq_recovery',\n",
    "       u'SR_1_total_score', u'SR_1_fa_rep', u'SR_1_hbond_sc',\n",
    "       u'SR_1_hbond_pm', u'SR_1_burunsat_pm',\n",
    "       u'SR_1_pstat_pm', u'SR_1_nlpstat_pm', u'SR_2_total_score',\n",
    "       u'SR_2_fa_rep', u'SR_2_hbond_sc', u'SR_2_all_cst', u'SR_2_hbond_pm',\n",
    "       u'SR_2_burunsat_pm', u'SR_2_pstat_pm', u'SR_2_nlpstat_pm', u'SR_3',\n",
    "       u'SR_3_total_score', u'SR_3_fa_rep', u'SR_3_hbond_sc', u'SR_3_all_cst',\n",
    "       u'SR_3_hbond_pm', u'SR_3_burunsat_pm', u'SR_3_pstat_pm',\n",
    "       u'SR_3_nlpstat_pm', u'SR_4', u'SR_4_total_score', u'SR_4_fa_rep',\n",
    "       u'SR_4_hbond_sc', u'SR_4_all_cst', u'SR_4_hbond_pm',\n",
    "       u'SR_4_burunsat_pm', u'SR_4_pstat_pm', u'SR_4_nlpstat_pm', u'SR_5',\n",
    "       u'SR_5_total_score', u'SR_5_fa_rep', u'SR_5_hbond_sc', u'SR_5_all_cst',\n",
    "       u'SR_5_interf_E_1_2', u'SR_5_dsasa_1_2', u'SR_5_hbond_pm',\n",
    "       u'SR_5_burunsat_pm', u'expression' ]\n",
    "\n",
    "x = x[ keep_cols ] \n",
    "\n",
    "y = x.expression.round().astype( bool )\n",
    "X = x.drop( u'expression', axis=1 )\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X = np.c_[X] #, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "###############################################################################\n",
    "# Classification and ROC analysis\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(y, n_folds=10)\n",
    "classifier = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
    "         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Decision Tree\",\n",
    "         \"Random Forest\", \"AdaBoost\", \"Naive Bayes\", \"Linear Discriminant Analysis\",\n",
    "         \"Quadratic Discriminant Analysis\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds in datasets:\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "    # and testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6)\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot also the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "        # and testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "figure.subplots_adjust(left=.02, right=.98)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "print X\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import pandas \n",
    "\n",
    "def low10( df ):\n",
    "    return df.sort_values( by='total_score' ).head( 10 ).mean()\n",
    "\n",
    "thermo = pandas.read_csv( 'data_sets/expression_data.csv', index_col='name' ) \n",
    "sf = pandas.read_csv( 'scorefile.csv' ) \n",
    "sf['name'] = sf.description.str.split( '_' ).str[ 1 ]\n",
    "\n",
    "grouped = sf.groupby( 'name' )\n",
    "low10 = grouped.apply( low10 )\n",
    "x = low10.join( thermo ).dropna()\n",
    "\n",
    "keep_cols = [ u'total_score', u'fa_rep', u'hbond_sc', \n",
    "       u'tot_pstat_pm', u'tot_nlpstat_pm', u'tot_burunsat_pm', u'tot_hbond_pm',\n",
    "       u'tot_NLconts_pm', u'tot_nlsurfaceE_pm', u'tot_total_charge',\n",
    "       u'tot_total_pos_charges', u'tot_total_neg_charges', u'tot_seq_recovery',\n",
    "       u'SR_1_total_score', u'SR_1_fa_rep', u'SR_1_hbond_sc',\n",
    "       u'SR_1_hbond_pm', u'SR_1_burunsat_pm',\n",
    "       u'SR_1_pstat_pm', u'SR_1_nlpstat_pm', u'SR_2_total_score',\n",
    "       u'SR_2_fa_rep', u'SR_2_hbond_sc', u'SR_2_all_cst', u'SR_2_hbond_pm',\n",
    "       u'SR_2_burunsat_pm', u'SR_2_pstat_pm', u'SR_2_nlpstat_pm', u'SR_3',\n",
    "       u'SR_3_total_score', u'SR_3_fa_rep', u'SR_3_hbond_sc', u'SR_3_all_cst',\n",
    "       u'SR_3_hbond_pm', u'SR_3_burunsat_pm', u'SR_3_pstat_pm',\n",
    "       u'SR_3_nlpstat_pm', u'SR_4', u'SR_4_total_score', u'SR_4_fa_rep',\n",
    "       u'SR_4_hbond_sc', u'SR_4_all_cst', u'SR_4_hbond_pm',\n",
    "       u'SR_4_burunsat_pm', u'SR_4_pstat_pm', u'SR_4_nlpstat_pm', u'SR_5',\n",
    "       u'SR_5_total_score', u'SR_5_fa_rep', u'SR_5_hbond_sc', u'SR_5_all_cst',\n",
    "       u'SR_5_interf_E_1_2', u'SR_5_dsasa_1_2', u'SR_5_hbond_pm',\n",
    "       u'SR_5_burunsat_pm', u'expression' ]\n",
    "\n",
    "x = x[ keep_cols ] \n",
    "y = x.expression.round().astype( bool )\n",
    "X = x.drop( u'expression', axis=1 )\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\n",
    "         #\"Nearest Neighbors\", \n",
    "         \"Linear SVM\", \"RBF SVM\", \"Decision Tree\",\n",
    "         \"Random Forest\", \"AdaBoost\", \n",
    "         #\"Naive Bayes\", \"Linear Discriminant Analysis\",\n",
    "         \"Quadratic Discriminant Analysis\"]\n",
    "classifiers = [\n",
    "    #KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    #GaussianNB(),\n",
    "    #LinearDiscriminantAnalysis(),\n",
    "    #QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [#make_moons(noise=0.3, random_state=0),\n",
    "            #make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds in datasets:\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "    # and testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6)\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "#     for name, clf in zip(names, classifiers):\n",
    "#         ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         score = clf.score(X_test, y_test)\n",
    "\n",
    "#         # Plot the decision boundary. For that, we will assign a color to each\n",
    "#         # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "#         if hasattr(clf, \"decision_function\"):\n",
    "#             Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "#         else:\n",
    "#             Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "#         # Put the result into a color plot\n",
    "#         Z = Z.reshape(xx.shape)\n",
    "#         ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "#         # Plot also the training points\n",
    "#         ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "#         # and testing points\n",
    "#         ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "#                    alpha=0.6)\n",
    "\n",
    "#         ax.set_xlim(xx.min(), xx.max())\n",
    "#         ax.set_ylim(yy.min(), yy.max())\n",
    "#         ax.set_xticks(())\n",
    "#         ax.set_yticks(())\n",
    "#         ax.set_title(name)\n",
    "#         ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "#                 size=15, horizontalalignment='right')\n",
    "#         i += 1\n",
    "\n",
    "figure.subplots_adjust(left=.02, right=.98)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
